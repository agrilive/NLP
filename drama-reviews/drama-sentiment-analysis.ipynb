{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drama Reviews Sentiment Analysis\n",
    "\n",
    "**Problem Statement:** Given drama reviews from mydramalist, the task is to predict whether a review contains positive, neutral or negative sentiment about the drama. This is a supervised learning task, where given a string of review text, we have to categorise them into predefined categories based on rating.\n",
    "\n",
    "**Solution:** After retrieving the reviews from the website, I have preprocessed the reviews text, as well as conduct exploratory data analysis on the ratings and the reviews. Here, I convert the text to numerical representation in order to be trained by a machine learning algorithm. Then, the algorithm will train and test the drama reviews sentiment.\n",
    "\n",
    "## 1. Import libraries and load CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('drama_reviews_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drama_title</th>\n",
       "      <th>user_name</th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>story_rating</th>\n",
       "      <th>cast_rating</th>\n",
       "      <th>music_rating</th>\n",
       "      <th>rewatch_value_rating</th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>reviews_processed</th>\n",
       "      <th>language</th>\n",
       "      <th>reviews_processed2x</th>\n",
       "      <th>reviews_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Dear My Friends (2016)</td>\n",
       "      <td>iamgeralddd</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Thank you writer Noh for making this heart-wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>thank you writer noh for making this heart war...</td>\n",
       "      <td>en</td>\n",
       "      <td>thank writer noh making heart warming story co...</td>\n",
       "      <td>heart warming story live drama excited weekend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Dear My Friends (2016)</td>\n",
       "      <td>Dounie</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>I know for some, stories following and tellin...</td>\n",
       "      <td>1</td>\n",
       "      <td>i know for some stories following and telling ...</td>\n",
       "      <td>en</td>\n",
       "      <td>know stories following telling lives older peo...</td>\n",
       "      <td>story old people promise boring decide try fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Dear My Friends (2016)</td>\n",
       "      <td>Pelin</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Story \"A realistic, cheerful story about “twi...</td>\n",
       "      <td>1</td>\n",
       "      <td>story a realistic cheerful story about twiligh...</td>\n",
       "      <td>en</td>\n",
       "      <td>story realistic cheerful story twilight youths...</td>\n",
       "      <td>story realistic cheerful story twilight young ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dear My Friends (2016)</td>\n",
       "      <td>silent_whispers</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>When I heard about a drama that would be comi...</td>\n",
       "      <td>1</td>\n",
       "      <td>when i heard about a drama that would be comin...</td>\n",
       "      <td>en</td>\n",
       "      <td>heard drama would coming 2016 twilight youths ...</td>\n",
       "      <td>drama twilight youth life long friend drama lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Dear My Friends (2016)</td>\n",
       "      <td>Dana</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>In a sometimes overwhelming world of perfect ...</td>\n",
       "      <td>1</td>\n",
       "      <td>in a sometimes overwhelming world of perfect f...</td>\n",
       "      <td>en</td>\n",
       "      <td>sometimes overwhelming world perfect faces scr...</td>\n",
       "      <td>overwhelming world perfect script dear friend ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              drama_title        user_name  overall_rating  story_rating  \\\n",
       "0  Dear My Friends (2016)      iamgeralddd            10.0          10.0   \n",
       "1  Dear My Friends (2016)           Dounie            10.0          10.0   \n",
       "2  Dear My Friends (2016)            Pelin            10.0          10.0   \n",
       "3  Dear My Friends (2016)  silent_whispers             9.0           9.0   \n",
       "4  Dear My Friends (2016)             Dana             9.0           9.0   \n",
       "\n",
       "   cast_rating  music_rating  rewatch_value_rating  \\\n",
       "0         10.0          10.0                  10.0   \n",
       "1         10.0           8.5                   9.0   \n",
       "2         10.0          10.0                  10.0   \n",
       "3         10.0          10.0                   7.0   \n",
       "4         10.0           7.0                   3.0   \n",
       "\n",
       "                                             reviews  sentiment  \\\n",
       "0   Thank you writer Noh for making this heart-wa...          1   \n",
       "1   I know for some, stories following and tellin...          1   \n",
       "2   Story \"A realistic, cheerful story about “twi...          1   \n",
       "3   When I heard about a drama that would be comi...          1   \n",
       "4   In a sometimes overwhelming world of perfect ...          1   \n",
       "\n",
       "                                   reviews_processed language  \\\n",
       "0  thank you writer noh for making this heart war...       en   \n",
       "1  i know for some stories following and telling ...       en   \n",
       "2  story a realistic cheerful story about twiligh...       en   \n",
       "3  when i heard about a drama that would be comin...       en   \n",
       "4  in a sometimes overwhelming world of perfect f...       en   \n",
       "\n",
       "                                 reviews_processed2x  \\\n",
       "0  thank writer noh making heart warming story co...   \n",
       "1  know stories following telling lives older peo...   \n",
       "2  story realistic cheerful story twilight youths...   \n",
       "3  heard drama would coming 2016 twilight youths ...   \n",
       "4  sometimes overwhelming world perfect faces scr...   \n",
       "\n",
       "                                  reviews_lemmatized  \n",
       "0  heart warming story live drama excited weekend...  \n",
       "1  story old people promise boring decide try fun...  \n",
       "2  story realistic cheerful story twilight young ...  \n",
       "3  drama twilight youth life long friend drama lo...  \n",
       "4  overwhelming world perfect script dear friend ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vectorization - Term Frequency & Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "From the exploratory data analysis, we found that the words \"drama\", \"story\" and \"character\" appeared very often. However, these common words may not be helpful in classification. Thus, TF-IDF is used to increase the significance of words that appear frequently in a document while decreasing the importance of common words that appear across all documents.\n",
    "\n",
    "TF-IDF is calculated as:\n",
    "- TF  = (Frequency of a word in doc)/(Total words in the doc)\n",
    "- IDF = Log((Total number of docs)/(Number of docs containing the word))\n",
    "\n",
    "df['reviews_processed'] is used here since the TfidfVectorizer in Scikit-Learn will factor in these stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_features = df['reviews_processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=2500, min_df=7, max_df=0.8, stop_words=stopwords.words('english'))\n",
    "processed_features = vectorizer.fit_transform(processed_features).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random Forest Classifier\n",
    "\n",
    "The Random Forest algorithm is an ensemble of many decision trees. An ensemble technique aggregates the outcome of individual predictions to get a better result and reduce overfitting. Random Forest is trained by bagging. Subsets of the training data are randomly sampled, fitted and the predicted outputs are aggregated. Sampling is done with replacement.\n",
    "\n",
    "### 4.1 Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Make predictions and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  51    0  177]\n",
      " [   0   35   97]\n",
      " [   0    0 4647]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.22      0.37       228\n",
      "           0       1.00      0.27      0.42       132\n",
      "           1       0.94      1.00      0.97      4647\n",
      "\n",
      "    accuracy                           0.95      5007\n",
      "   macro avg       0.98      0.50      0.59      5007\n",
      "weighted avg       0.95      0.95      0.93      5007\n",
      "\n",
      "0.945276612742161\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The acurracy level does not reveal the effectiveness of the model as the size of the positive sentiment class outweighs the negative and neutral sentiment classes. Thus, we look into other metrics to identify the effectiveness of the model.\n",
    "\n",
    "From the confusion matrix, we can see that there is a high proportion of negative reviews (177/228) wrongly predicted as positive reviews. Although a similarly high proportion of neutral reviews (97/132) were wrongly predicted as positive reviews, a rating of 5.0/10.0 would be considered positive under a binary classification problem of negative or positive reviews. As such, a binary classification task could be tested as well.\n",
    "\n",
    "It is noteworthy to say that the precision values are high, meaning to say that there is a high propotion of true positives relative to false positives. Yet, recall score is sacrificed. A high proportion of negative and neutral reviews were wrongly classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Logistic Regression\n",
    "\n",
    "Logistic Regression is a classification algorithm, which predicts the probability that an input belong to a particular category. The Logistic Regression models data using the sigmoid function, g(z)=1/(1+e^-z).\n",
    "\n",
    "### 5.1 Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state=42, solver='lbfgs', multi_class='ovr')\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Make predictions and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  36    0  192]\n",
      " [   4    0  128]\n",
      " [   9    0 4638]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.16      0.26       228\n",
      "           0       0.00      0.00      0.00       132\n",
      "           1       0.94      1.00      0.97      4647\n",
      "\n",
      "    accuracy                           0.93      5007\n",
      "   macro avg       0.56      0.39      0.41      5007\n",
      "weighted avg       0.90      0.93      0.91      5007\n",
      "\n",
      "0.9334931096464949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weich\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although accuracy is almost as high as the one given by the random forest algorithm, closer analysis is needed to evaluate the effectiveness of the logistic regression model.\n",
    "\n",
    "The precision and recall scores of positive reviews are high, while that of negative and neutral reviews are significantly lower. This could be contributed to the fact that none of the neutral reviews were correctly predicted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Support Vector Machine\n",
    "\n",
    "Support Vector Machine algorithms find the hyperplane that best divides the dataset into its classes. Support Vectors are the data points nearest to the hyperplane, which changes the hyperplane position if removed.\n",
    "\n",
    "### 6.1 Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm = svm.LinearSVC(random_state=42)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Make predictions and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  95   10  123]\n",
      " [   9   16  107]\n",
      " [  49   16 4582]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.42      0.50       228\n",
      "           0       0.38      0.12      0.18       132\n",
      "           1       0.95      0.99      0.97      4647\n",
      "\n",
      "    accuracy                           0.94      5007\n",
      "   macro avg       0.65      0.51      0.55      5007\n",
      "weighted avg       0.92      0.94      0.93      5007\n",
      "\n",
      "0.9372877970840823\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the support vector machine seem to be rather similar to that of the logistic regression, with high precision and recall scores for positive reviews, and lower scores for negative and neutral reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. K-Nearest Neighbors\n",
    "\n",
    "K-Nearest Neighbors algorithm classifies data into classes based on a similiarity measure.\n",
    "\n",
    "### 7.1 Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Make predictions and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  25    6  197]\n",
      " [   7    3  122]\n",
      " [  18   10 4619]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.50      0.11      0.18       228\n",
      "           0       0.16      0.02      0.04       132\n",
      "           1       0.94      0.99      0.96      4647\n",
      "\n",
      "    accuracy                           0.93      5007\n",
      "   macro avg       0.53      0.38      0.39      5007\n",
      "weighted avg       0.90      0.93      0.90      5007\n",
      "\n",
      "0.9281006590772918\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the k-nearest neighbors algorithm give high precision and recall scores for positive reviews and lower scores for negative and neutral reviews.\n",
    "\n",
    "## 8. Hyperparameter Tuning - Random Forest Classifier\n",
    "\n",
    "Despite the high accuracy and precision scores for the random forest classifier, the best parameters may not have been selected. As such, a **Grid Search Cross Validation** would be used to identify the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=200, n_jobs=-1,\n",
       "                                              oob_score=True, random_state=42,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [200, 400, 600]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1,n_estimators=200, oob_score = True, random_state=42) \n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 400, 600],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'auto', 'n_estimators': 200}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_params_ # best parameters of grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rfc = CV_rfc.best_estimator_\n",
    "y_pred = best_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  51    0  177]\n",
      " [   0   35   97]\n",
      " [   0    0 4647]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.22      0.37       228\n",
      "           0       1.00      0.27      0.42       132\n",
      "           1       0.94      1.00      0.97      4647\n",
      "\n",
      "    accuracy                           0.95      5007\n",
      "   macro avg       0.98      0.50      0.59      5007\n",
      "weighted avg       0.95      0.95      0.93      5007\n",
      "\n",
      "0.945276612742161\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the parameters I tested, the best parameters are the same as the Random Forest Classifier I had tried earlier. \n",
    "\n",
    "For further analysis, I will make two changes and use the Random Forest Classifier to train and predict the sentiments again.\n",
    "\n",
    "## 9. Binary Class & Down Sample the Majority Class\n",
    "\n",
    "Since the Random Forest Classifier predicted a huge proportion of neutral sentiments as positive, I combined the neutral and positive sentiments into one class - positive. Thus, this will be a binary classification problem.\n",
    "\n",
    "In addition, accuracy was not a good indicator of model effectiveness as the size of the positive sentiment class far outweighs the negative class. Thus, I will down sample the majority positive class.\n",
    "\n",
    "### 9.1 Convert data to binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentiment(row): # label sentiment according to overall rating\n",
    "    if row['overall_rating'] < 5.0:\n",
    "        return 0 # 0 means negative rating\n",
    "    return 1 # 1 means positive rating\n",
    "\n",
    "df['sentiment'] = df.apply(lambda row: label_sentiment(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    23867\n",
       "0     1167\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts() # data is skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Down sample positive sentiment reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1167\n",
       "0    1167\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = df[df['sentiment']==1] # Separate majority and minority classes\n",
    "df_minority = df[df['sentiment']==0]\n",
    "\n",
    "df_majority_downsampled = resample(df_majority, replace=False, n_samples=len(df_minority), random_state=42)\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority]) # Combine minority class with downsampled majority class\n",
    "df_downsampled['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Random Forest Classifier with best parameters\n",
    "\n",
    "The downsampled data is then trained with the random forest classifier and its best parameters.\n",
    "\n",
    "### 10.1 Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_features = df_downsampled['reviews_processed']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=2500, min_df=7, max_df=0.8, stop_words=stopwords.words('english')) # vectorization\n",
    "processed_features = vectorizer.fit_transform(processed_features).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_downsampled['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_features, labels, test_size=0.2, random_state=42) \n",
    "#split train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Train Random Forest Classifier with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4 Make predictions and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[205  30]\n",
      " [ 49 183]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       235\n",
      "           1       0.86      0.79      0.82       232\n",
      "\n",
      "    accuracy                           0.83       467\n",
      "   macro avg       0.83      0.83      0.83       467\n",
      "weighted avg       0.83      0.83      0.83       467\n",
      "\n",
      "0.8308351177730193\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score now gives a better view on the effectiveness of the model. The precision and recall scores are roughly similar as well. \n",
    "\n",
    "### 10.5 Receiver Operating Characteristics curve\n",
    "\n",
    "To view the trade-off between sensitivity and specificity, we can use the Receiver Operating Characteristics curve. This allows us to choose a threshold that balances sensitivity and specificity. Sensitivity is the true positive rate while specificity is the true negative rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_probs = rfc.predict_proba(X_test)\n",
    "y_pred_probs = y_probs[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steep curve reveals a positive sign. We are maximising the true positive rate while minimising the false positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9150678650036683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target value for Area Under Curve (AUC) is 1, and this model gives a value of 0.915 - pretty close!\n",
    "\n",
    "## 11. Closing Thoughts\n",
    "\n",
    "This is the first end-to-end project that I did, from getting the data, processing it and training machine learning algorithm for a classification project. I struggled with data retrieval as I had not learnt web scraping before. It was a challenge putting the data into a DataFrame as it tested my for loop and regular expression skills. \n",
    "\n",
    "Data pre-processing was almost as challenging. The first time I did it gave funny words like \"gth\", \"seriesi\" \"hormones\" and even \"shitpeace\" as most commonly occuring words for the negative sentiments! It took several iterations back and forth between data pre-processing and exploratory data analysis to get it right.\n",
    "\n",
    "I am thoroughly thankful that this mini project I have worked on for close to a month has come to fruition. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
