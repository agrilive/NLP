{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification using ULMFiT and fastai Library.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPdTCBJ65Hau",
        "colab_type": "text"
      },
      "source": [
        "# Text Classification using ULMFit and fastai Library\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krhdGulu3bO8",
        "colab_type": "text"
      },
      "source": [
        "ULMFiT is a transfer learning method for any NLP task. Transfer learning involves using pre-trained deep learning models and adapting them to our problems. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyBOYIDWynwI",
        "colab_type": "text"
      },
      "source": [
        "**Problem Statement**\n",
        "\n",
        "Fine-tune a pre-trained model and use it for text classification on a new dataset. Since the dataset is small (<1000 labeled instances), a neural network model trained from scratch would overfit it.\n",
        "\n",
        "**Dataset:** 20 Newsgroup dataset available in sklearn.datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU3-i84iyICR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "outputId": "a541a717-b39b-441e-83d5-f82345e0cfd7"
      },
      "source": [
        "# install PyTorch and fastai into the Colab environment\n",
        "!pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
        "!pip install fastai"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
            "Collecting torch_nightly\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/nightly/cu92/torch_nightly-1.2.0.dev20190805%2Bcu92-cp36-cp36m-linux_x86_64.whl (704.8MB)\n",
            "\u001b[K     |████████████████████████████████| 704.8MB 25kB/s \n",
            "\u001b[?25hInstalling collected packages: torch-nightly\n",
            "Successfully installed torch-nightly-1.2.0.dev20190805+cu92\n",
            "Requirement already satisfied: fastai in /usr/local/lib/python3.6/dist-packages (1.0.59)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.21.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai) (0.4.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai) (2.7.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (0.25.3)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.3.1)\n",
            "Requirement already satisfied: fastprogress>=0.1.19 in /usr/local/lib/python3.6/dist-packages (from fastai) (0.1.22)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai) (4.6.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (3.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.1.9)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.17.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (4.3.0)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai) (1.3.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.3.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai) (19.2)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai) (7.352.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->fastai) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.4.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.4.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.2.0)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (7.0.8)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.9.6)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (1.0.2)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (2.0.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai) (0.46)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->fastai) (42.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy>=2.0.18->fastai) (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laJwN_0Zyh0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libraries\n",
        "import fastai\n",
        "from fastai import *\n",
        "from fastai.text import * \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import io\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lvkd6iTzQ9N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b01a57a4-aafe-4d97-ee78-f2b5932f2041"
      },
      "source": [
        "# import dataset\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
        "documents = dataset.data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo6z5uYhzXyV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "2b6b26f0-a944-464a-8a99-f14de73a3ca0"
      },
      "source": [
        "df = pd.DataFrame({'label':dataset.target, 'text':dataset.data})\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17</td>\n",
              "      <td>Well i'm not sure about the story nad it did s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17</td>\n",
              "      <td>Although I realize that principle is not one o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>Notwithstanding all the legitimate fuss about ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>Well, I will have to change the scoring on my ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0     17  Well i'm not sure about the story nad it did s...\n",
              "1      0  \\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...\n",
              "2     17  Although I realize that principle is not one o...\n",
              "3     11  Notwithstanding all the legitimate fuss about ...\n",
              "4     10  Well, I will have to change the scoring on my ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ8-XegBzguS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ba3fccb5-4db9-4310-9a20-dce7e3391da3"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGEpkU9f0iZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df[df['label'].isin([10,15])]\n",
        "df = df.reset_index(drop = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnQdcravzhoi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "e093aa8b-1a34-4c57-9760-6e7b61cef1ce"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10    600\n",
              "15    599\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCOfahan0rHm",
        "colab_type": "text"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqFLf3zk0H_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove non-alphabets\n",
        "df['text'] = df['text'].str.replace(\"[^a-zA-Z]\", \" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW17QAHO01N3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "152a5580-a10b-4cb1-8b53-24ef89ec66b9"
      },
      "source": [
        "# download nltk package\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords \n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha35USVF04Qn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenization \n",
        "tokenized_doc = df['text'].apply(lambda x: x.split())\n",
        "\n",
        "# remove stop-words \n",
        "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
        "\n",
        "# de-tokenization \n",
        "detokenized_doc = [] \n",
        "for i in range(len(df)): \n",
        "    t = ' '.join(tokenized_doc[i]) \n",
        "    detokenized_doc.append(t) \n",
        "\n",
        "df['text'] = detokenized_doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0InqcW91Bsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split data into training and validation set\n",
        "df_trn, df_val = train_test_split(df, stratify = df['label'], test_size = 0.3, random_state = 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sWFfDVA1MAT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ca4b8423-89d3-4b1f-c182-60be191edba8"
      },
      "source": [
        "# Language model data\n",
        "data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val, path = \"\")\n",
        "\n",
        "# Classifier model data\n",
        "data_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn, valid_df = df_val, vocab=data_lm.train_ds.vocab, bs=32)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57Dha9sX1cUr",
        "colab_type": "text"
      },
      "source": [
        "**Fine-Tuning the Pre-Trained Model and Making Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2gSD8qB1WBy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "707d4d35-53f8-44f3-83ba-4ede615347b0"
      },
      "source": [
        "# create a learner object that will create a model, download the pre-trained weights, and be ready for fine-tuning\n",
        "learn = language_model_learner(data_lm, arch = AWD_LSTM, drop_mult=0.7)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBu67Naz1nvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "fd3ea404-88e2-43ae-8869-36f765712fc8"
      },
      "source": [
        "# train the learner object with learning rate = 1e-2\n",
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>6.110006</td>\n",
              "      <td>5.188154</td>\n",
              "      <td>0.262036</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8jJgscz2DDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save encoder \n",
        "learn.save_encoder('ft_enc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18PXdPx12KUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c1c1835-6c4e-4059-c2ba-56e6b16804e4"
      },
      "source": [
        "# use data_clas object created earlier to build a classifier with the fine-tuned encoder\n",
        "learn = text_classifier_learner(data_clas, arch = AWD_LSTM, drop_mult=0.7)\n",
        "learn.load_encoder('ft_enc')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (839 items)\n",
              "x: TextList\n",
              "xxbos xxmaj from account sound like even saw goal xxmaj mike xxmaj smith came behind net fired xxunk pass hit xxmaj fuhr back leg xxmaj fuhr backing time never saw happened xxmaj the puck went straight xxmaj fuhr leg net xxmaj fuhr never chance xxmaj there play back goaltender fact xxmaj xxunk xxmaj xxunk xxmaj calgary dumped xxmaj smith xxunk xxmaj it unfortunate happened xxmaj smith nice guy rookie time birthday xxmaj but blame lies xxmaj starting pee wee coaches tell players never make cross ice pass front net xxmaj too much chance intercepted hitting goaltender whatever xxmaj and people say xxmaj smith cost xxmaj oilers series i say certainly cause team lose three games xxmaj there reason xxunk team like xxmaj edmonton tied late third period th game second round xxmaj everybody team take responsibility even situation,xxbos xxmaj yes xxmaj he also played xxmaj jesus xxmaj jesus xxmaj christ xxmaj superstar became xxmaj christian xxmaj he played xxmaj black xxmaj sabbath right first got saved left,xxbos i impression objective find conclusive evidence puck cross line xxmaj and replays i saw showed fairly xxunk puck cross goal line time anyway xxmaj somebody screwed,xxbos xxunk xxunk student xxunk couple months ago wanted know answer far could tell although story never specifically told bible many references made primarily new testament old testament actually entirely different view satan excuse pun devil advocate xxunk see book job getting back fallen angel story references xxunk bible except xxunk morning star king james version isaiah probably referred babylonian xxunk much sun king referred louis xxunk know story came may rolling around long time milton paradise lost may xxunk sorry xxunk rest hurry need eat lunch feel free email stuff found although lot result bible concordance program called xxunk really lousy way buy,xxbos xxmaj in response debate better season xxmaj jagr xxmaj francis i think xxmaj jagr probably better point per minute ice time stats exist properly xxunk xxunk better useful statistic xxmaj if player ice team scores lot goals allows goals must something right xxmaj it especially useful compare xxunk play team roughly similar xxunk equally good players xxmaj it xxunk varying xxunk success compare players different teams i agree would nice xxup nhl keep statistics useful ones suggest xxmaj total ice time would useful missing stat xxmaj jagr vs xxmaj francis arguments xxmaj somehow xxunk quality ice time suggest would useless xxmaj it would better stat evaluating coaching ie players given quality ice time actually talented ones a good player could given low amounts quality ice time team depth stupid coach recognize talent bad player could given lots quality ice time lack team depth stupid coach thinks effective player xxmaj this stat would much flawed almost conclusions could xxunk regarding player talent useful stat xxmaj it quite useful evaluating player talent xxmaj you one displaying ignorance xxunk see ice goals scored allowed positive thing xxunk\n",
              "y: CategoryList\n",
              "10,15,10,15,10\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (360 items)\n",
              "x: TextList\n",
              "xxbos xxmaj first xxmaj happy xxmaj birthday xxmaj xxunk xxmaj second xxup espn affinity xxmaj patrick probably travel production costs week xxup xxunk xxmaj national xxmaj hockey xxmaj night xxunk xxup espn xxup abc owner xxmaj capital xxmaj cities company known quite xxunk minimal xxunk costs xxmaj it quite possible xxmaj jim xxmaj xxunk may working xxunk xxmaj gary xxmaj thorne xxmaj bill xxmaj clement xxup nj based rest xxup espn xxunk xxunk xxunk xxup xxunk close xxunk tri state area xxmaj plus makes sense terms solid hockey following northeast xxunk xxup pa xxup ny xxup nj xxup dc xxmaj xxunk xxmaj whereas xxmaj adams xxmaj american based teams xxmaj buffalo xxmaj hartford xxmaj top xxup us xxup tv markets,xxbos xxmaj sorry taking xxmaj xxunk xxunk i also like add verses perhaps answer second q xxmaj verses xxmaj corinthians xxmaj colossians xxmaj as knowing bit xxunk xxmaj people normally xxunk warn xxmaj however case conscience hardened sin xxunk xxmaj hebrews person idea care sinning xxmaj of course sins know sinful begin xxmaj those take searching xxunk xxmaj scripture find sinful repent change xxmaj the best question ask every xxunk judge sinful possibilities xxmaj would xxmaj jesus xxunk point time i know sounds like xxunk truly xxunk question xxmaj joe xxmaj fisher,xxbos xxmaj could anyone recommend mail order xxunk hockey xxunk xxmaj thanks xxmaj advance xxmaj wayne,xxbos xxmaj you ask i would echo question i trying xxunk xxmaj but assuming xxmaj pope universal jurisdiction authority authority rely upon decisions xxmaj what prevents choosing xxup any doctrine i like saying xxmaj papal disagreement error resolved time xxmaj this especially true since xxmaj councils xxmaj bishops basically stood xxmaj pope xxmaj it appears much lies heart matter disagreements tradition xxmaj tradition also authority discipline xxmaj my question xxunk xxup sspx xxmaj is xxup any way positions respect church xxunk could change conformed xxmaj pope assuming xxmaj pope position change leaders xxup sspx jointly make choice xxmaj if appears claiming infallible teaching authority xxmaj if i adopt view i xxup not wrong i xxup can t wrong xxup no xxup way i change mind xxup you must change i either left xxmaj catholic xxmaj church left xxmaj the xxmaj orthodox xxmaj church recognize papal authority jurisdiction xxunk authority present bishop xxmaj ecumenical xxmaj councils xxmaj we regard subsequent development doctrines regarding papal authority jurisdiction separation xxmaj bishop xxmaj rome xxmaj orthodox church xxmaj without going merits xxmaj great xxmaj schism least xxmaj orthodox agree split occurred xxunk appear xxunk games like xxmaj he xxmaj pope recognize effective xxmaj words aside appears de xxunk split xxmaj we xxunk argue xxmaj second xxmaj coming real traditional teaching xxmaj church xxmaj if simple matter xxmaj east xxmaj west would separated years i thought teaching xxunk church allow error teachings regarding faith morals even short term i may wrong i xxmaj roman xxmaj catholic xxmaj what would effect xxmaj pope making ex cathedra statement regarding xxup sspx situation xxmaj would honored xxmaj if get around formal doctrine infallibility xxmaj again i trying xxunk i trying understand xxmaj since i xxmaj orthodox i got real vested interest outcome one way xxmaj it command legitimate xxup sspx view xxmaj pope commands legitimate xxmaj why xxmaj this xxup very slippery slope xxmaj true enough xxmaj one could argue establishing non xxunk jurisdiction i know even concept problem xxmaj catholic circles xxmaj larry xxmaj overacker llo shell com,xxbos xxmaj ottawa picks first fewer wins season first tiebreaker xxmaj keith xxmaj keller xxup let s xxup go xxup rangers xxup let s xxup go xxup quakers kkeller mail sas upenn edu xxup ivy xxup league xxup champs\n",
              "y: CategoryList\n",
              "10,15,10,15,10\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(7672, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(7672, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f381e4c08c8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (839 items)\n",
              "x: TextList\n",
              "xxbos xxmaj from account sound like even saw goal xxmaj mike xxmaj smith came behind net fired xxunk pass hit xxmaj fuhr back leg xxmaj fuhr backing time never saw happened xxmaj the puck went straight xxmaj fuhr leg net xxmaj fuhr never chance xxmaj there play back goaltender fact xxmaj xxunk xxmaj xxunk xxmaj calgary dumped xxmaj smith xxunk xxmaj it unfortunate happened xxmaj smith nice guy rookie time birthday xxmaj but blame lies xxmaj starting pee wee coaches tell players never make cross ice pass front net xxmaj too much chance intercepted hitting goaltender whatever xxmaj and people say xxmaj smith cost xxmaj oilers series i say certainly cause team lose three games xxmaj there reason xxunk team like xxmaj edmonton tied late third period th game second round xxmaj everybody team take responsibility even situation,xxbos xxmaj yes xxmaj he also played xxmaj jesus xxmaj jesus xxmaj christ xxmaj superstar became xxmaj christian xxmaj he played xxmaj black xxmaj sabbath right first got saved left,xxbos i impression objective find conclusive evidence puck cross line xxmaj and replays i saw showed fairly xxunk puck cross goal line time anyway xxmaj somebody screwed,xxbos xxunk xxunk student xxunk couple months ago wanted know answer far could tell although story never specifically told bible many references made primarily new testament old testament actually entirely different view satan excuse pun devil advocate xxunk see book job getting back fallen angel story references xxunk bible except xxunk morning star king james version isaiah probably referred babylonian xxunk much sun king referred louis xxunk know story came may rolling around long time milton paradise lost may xxunk sorry xxunk rest hurry need eat lunch feel free email stuff found although lot result bible concordance program called xxunk really lousy way buy,xxbos xxmaj in response debate better season xxmaj jagr xxmaj francis i think xxmaj jagr probably better point per minute ice time stats exist properly xxunk xxunk better useful statistic xxmaj if player ice team scores lot goals allows goals must something right xxmaj it especially useful compare xxunk play team roughly similar xxunk equally good players xxmaj it xxunk varying xxunk success compare players different teams i agree would nice xxup nhl keep statistics useful ones suggest xxmaj total ice time would useful missing stat xxmaj jagr vs xxmaj francis arguments xxmaj somehow xxunk quality ice time suggest would useless xxmaj it would better stat evaluating coaching ie players given quality ice time actually talented ones a good player could given low amounts quality ice time team depth stupid coach recognize talent bad player could given lots quality ice time lack team depth stupid coach thinks effective player xxmaj this stat would much flawed almost conclusions could xxunk regarding player talent useful stat xxmaj it quite useful evaluating player talent xxmaj you one displaying ignorance xxunk see ice goals scored allowed positive thing xxunk\n",
              "y: CategoryList\n",
              "10,15,10,15,10\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (360 items)\n",
              "x: TextList\n",
              "xxbos xxmaj first xxmaj happy xxmaj birthday xxmaj xxunk xxmaj second xxup espn affinity xxmaj patrick probably travel production costs week xxup xxunk xxmaj national xxmaj hockey xxmaj night xxunk xxup espn xxup abc owner xxmaj capital xxmaj cities company known quite xxunk minimal xxunk costs xxmaj it quite possible xxmaj jim xxmaj xxunk may working xxunk xxmaj gary xxmaj thorne xxmaj bill xxmaj clement xxup nj based rest xxup espn xxunk xxunk xxunk xxup xxunk close xxunk tri state area xxmaj plus makes sense terms solid hockey following northeast xxunk xxup pa xxup ny xxup nj xxup dc xxmaj xxunk xxmaj whereas xxmaj adams xxmaj american based teams xxmaj buffalo xxmaj hartford xxmaj top xxup us xxup tv markets,xxbos xxmaj sorry taking xxmaj xxunk xxunk i also like add verses perhaps answer second q xxmaj verses xxmaj corinthians xxmaj colossians xxmaj as knowing bit xxunk xxmaj people normally xxunk warn xxmaj however case conscience hardened sin xxunk xxmaj hebrews person idea care sinning xxmaj of course sins know sinful begin xxmaj those take searching xxunk xxmaj scripture find sinful repent change xxmaj the best question ask every xxunk judge sinful possibilities xxmaj would xxmaj jesus xxunk point time i know sounds like xxunk truly xxunk question xxmaj joe xxmaj fisher,xxbos xxmaj could anyone recommend mail order xxunk hockey xxunk xxmaj thanks xxmaj advance xxmaj wayne,xxbos xxmaj you ask i would echo question i trying xxunk xxmaj but assuming xxmaj pope universal jurisdiction authority authority rely upon decisions xxmaj what prevents choosing xxup any doctrine i like saying xxmaj papal disagreement error resolved time xxmaj this especially true since xxmaj councils xxmaj bishops basically stood xxmaj pope xxmaj it appears much lies heart matter disagreements tradition xxmaj tradition also authority discipline xxmaj my question xxunk xxup sspx xxmaj is xxup any way positions respect church xxunk could change conformed xxmaj pope assuming xxmaj pope position change leaders xxup sspx jointly make choice xxmaj if appears claiming infallible teaching authority xxmaj if i adopt view i xxup not wrong i xxup can t wrong xxup no xxup way i change mind xxup you must change i either left xxmaj catholic xxmaj church left xxmaj the xxmaj orthodox xxmaj church recognize papal authority jurisdiction xxunk authority present bishop xxmaj ecumenical xxmaj councils xxmaj we regard subsequent development doctrines regarding papal authority jurisdiction separation xxmaj bishop xxmaj rome xxmaj orthodox church xxmaj without going merits xxmaj great xxmaj schism least xxmaj orthodox agree split occurred xxunk appear xxunk games like xxmaj he xxmaj pope recognize effective xxmaj words aside appears de xxunk split xxmaj we xxunk argue xxmaj second xxmaj coming real traditional teaching xxmaj church xxmaj if simple matter xxmaj east xxmaj west would separated years i thought teaching xxunk church allow error teachings regarding faith morals even short term i may wrong i xxmaj roman xxmaj catholic xxmaj what would effect xxmaj pope making ex cathedra statement regarding xxup sspx situation xxmaj would honored xxmaj if get around formal doctrine infallibility xxmaj again i trying xxunk i trying understand xxmaj since i xxmaj orthodox i got real vested interest outcome one way xxmaj it command legitimate xxup sspx view xxmaj pope commands legitimate xxmaj why xxmaj this xxup very slippery slope xxmaj true enough xxmaj one could argue establishing non xxunk jurisdiction i know even concept problem xxmaj catholic circles xxmaj larry xxmaj overacker llo shell com,xxbos xxmaj ottawa picks first fewer wins season first tiebreaker xxmaj keith xxmaj keller xxup let s xxup go xxup rangers xxup let s xxup go xxup quakers kkeller mail sas upenn edu xxup ivy xxup league xxup champs\n",
              "y: CategoryList\n",
              "10,15,10,15,10\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(7672, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(7672, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f381e4c08c8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(7672, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(7672, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(7672, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(7672, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JUqHLvD2X27",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "c945293e-f6fc-4267-9ee6-81828ad416b1"
      },
      "source": [
        "# fit model again\n",
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.367993</td>\n",
              "      <td>0.197450</td>\n",
              "      <td>0.930556</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg_uHEMo21Ps",
        "colab_type": "text"
      },
      "source": [
        "Accuracy increased! The validation loss is less than the training loss as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBTp4_Bo2mW7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "f0ebebba-dae9-484d-ca2c-b2ca5164e1fc"
      },
      "source": [
        "# get predictions\n",
        "preds, targets = learn.get_preds()\n",
        "\n",
        "predictions = np.argmax(preds, axis = 1)\n",
        "pd.crosstab(predictions, targets)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>159</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>176</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0    0    1\n",
              "row_0          \n",
              "0      159    4\n",
              "1       21  176"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VJn_wOf2_PE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBfolQqp5ghP",
        "colab_type": "text"
      },
      "source": [
        "Adapted from: https://www.analyticsvidhya.com/blog/2018/11/tutorial-text-classification-ulmfit-fastai-library/"
      ]
    }
  ]
}